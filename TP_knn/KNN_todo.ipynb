{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@authors:  Joseph Salmon, Alex Gramfort, Claire Vernade, Mathurin Massias\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "from tp_knn_source import (rand_gauss, rand_bi_gauss, rand_tri_gauss,\n",
    "                           rand_checkers, rand_clown, plot_2d, ErrorCurve,\n",
    "                           frontiere_new, LOOCurve)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "\n",
    "plt.close('all')\n",
    "rc('font', **{'family': 'sans-serif', 'sans-serif': ['Computer Modern Roman']})\n",
    "params = {'axes.labelsize': 12,\n",
    "          'font.size': 16,\n",
    "          'legend.fontsize': 16,\n",
    "          'text.usetex': False,\n",
    "          'figure.figsize': (8, 6)}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.set_style(\"white\")\n",
    "_ = sns.axes_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#     Data Generation: example\n",
    "############################################################################\n",
    "\n",
    "np.random.seed(42)  # fix seed globally\n",
    "\n",
    "n = 100\n",
    "\n",
    "rand_gauss(n, mu, sigma)\n",
    "\n",
    "n1 = 20\n",
    "n2 = 20\n",
    "# TODO for four functions\n",
    "X1, y1 = rand_bi_gauss()\n",
    "\n",
    "n1 = 50\n",
    "n2 = 50\n",
    "n3 = 50\n",
    "X2, y2 = rand_tri_gauss()\n",
    "\n",
    "n1 = 50\n",
    "n2 = 50\n",
    "\n",
    "X3, y3 = rand_checkers\n",
    "\n",
    "n1 = 150\n",
    "n2 = 150\n",
    "X4, y4 = rand_clown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#     Displaying labeled data\n",
    "############################################################################\n",
    "\n",
    "plt.show()\n",
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "plt.figure(1, figsize=(15, 5))\n",
    "plt.subplot(141)\n",
    "plt.title('First data set')\n",
    "plot_2d(X1, y1)\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title('Second data set')\n",
    "# todo plot,\n",
    "# todo other datasets on other subplots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#     K-NN\n",
    "############################################################################\n",
    "\n",
    "# Q2 : Write your own implementation\n",
    "\n",
    "\n",
    "class KNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" Home made KNN Classifier class\"\"\"\n",
    "    def __init__(self, n_neighbors=1):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        # TODO : Compute all pairwise distances between X and self.X_\n",
    "\n",
    "        # TODO : Get indices to sort them\n",
    "\n",
    "        # TODO Get indices of neighbors\n",
    "\n",
    "        # TODO: Get labels of neighbors\n",
    "        Y_neighbors = # TODO\n",
    "\n",
    "        # TODO : Find the predicted labels y for each entry in X\n",
    "        # You can use the scipy.stats.mode function\n",
    "        y_pred = # TODO\n",
    "        return y_pred\n",
    "\n",
    "# TODO : compare your implementation with scikit-learn\n",
    "\n",
    "# Focus on dataset 2\n",
    "X_train = X2[::2]\n",
    "Y_train = \n",
    "X_test = \n",
    "Y_test = \n",
    "\n",
    "# TODO\n",
    "\n",
    "# your classifier\n",
    "n_neighbors = 1\n",
    "knn = KNNClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "Y_pred = # TODO\n",
    "\n",
    "sknn = # TODO\n",
    "Y_pred_skl = # todo\n",
    "\n",
    "# TODO check that all labels match\n",
    "\n",
    "# From now on use the Scikit-Learn implementation\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Q3 : test now all datasets\n",
    "\n",
    "n_neighbors = 5  # the k in k-NN\n",
    "knn = neighbors.KNeighborsClassifier # todo\n",
    "\n",
    "\n",
    "# TODO something like:\n",
    "# for data in [data1, data2, data3, data4]:\n",
    "    # TODO: fit your knn in the loop\n",
    "    \n",
    "    plt.figure()\n",
    "    #todo plot\n",
    "    n_labels = # TODO\n",
    "    frontiere_new(knn, X, y, w=None, step=50, alpha_choice=1,\n",
    "                  n_labels=n_labels, n_neighbors=n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Display the result when varying the value of K\n",
    "\n",
    "\n",
    "plt.figure(3, figsize=(12, 8))\n",
    "plt.subplot(3, 5, 3)\n",
    "plot_2d(X_train, Y_train)\n",
    "plt.xlabel('Samples')\n",
    "ax = plt.gca()\n",
    "ax.get_yaxis().set_ticks([])\n",
    "ax.get_xaxis().set_ticks([])\n",
    "\n",
    "for n_neighbors in # TODO:\n",
    "    # TODO \n",
    "    plt.subplot(3, 5, 5 + n_neighbors)\n",
    "    # todo put a label indicating the number of labels\n",
    "    \n",
    "\n",
    "    frontiere_new(knn, X, y, w=None, step=50, alpha_choice=1,\n",
    "                  colorbar=False, samples=False)\n",
    "    plt.draw()  # update plot\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Weighted k-NN\n",
    "\n",
    "\n",
    "def weights(dist):\n",
    "    \"\"\"Returns an array of weights, exponentially decreasing in the square\n",
    "    of the distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dist : a one-dimensional array of distances.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weight : array of the same size as dist\n",
    "    \"\"\"\n",
    "    # TODO: use weights equal to exp(- dist^2 / 0.1)\n",
    "    return # TODO\n",
    "\n",
    "n_neighbors = 5\n",
    "wknn = # TODO\n",
    "wknn.fit(X_train, Y_train)\n",
    "plt.figure(4)\n",
    "plot_2d(X_train, Y_train)\n",
    "\n",
    "\n",
    "frontiere_new(knn, X_train, Y_train, w=None, step=50, alpha_choice=1)\n",
    "\n",
    "print(wknn.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 : Scores on train data\n",
    "n_neighbors = 1\n",
    "\n",
    "\n",
    "\n",
    "# TODO use knn.score, on test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 : Scores on left out data\n",
    "\n",
    "n1 = n2 = 200\n",
    "sigma = 0.1\n",
    "data4 = rand_checkers(2 * n1, 2 * n2, sigma)\n",
    "\n",
    "X_train = X4[::2]\n",
    "Y_train = y4[::2].astype(int)\n",
    "X_test = X4[1::2]\n",
    "Y_test = y4[1::2].astype(int)\n",
    "\n",
    "\n",
    "# TODO instantiate ErrorCurve with k_range=range(1, 51)\n",
    "error_curve = \n",
    "# TODO fit it, plot it\n",
    "\n",
    "plt.figure(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(5)\n",
    "collist = ['blue', 'grey', 'red', 'purple', 'orange', 'salmon', 'black',\n",
    "           'fuchsia']\n",
    "\n",
    "sigma = 0.1\n",
    "plt.figure(5)\n",
    "range_n_samples = [100, 500, 1000]\n",
    "niter = len(range_n_samples)\n",
    "for n in range(niter):\n",
    "    n1 = n2 = range_n_samples[n]\n",
    "    X_train, Y_train = rand_checkers(n1, n2, sigma)\n",
    "    X_test, Y_test = rand_checkers(n1, n2, sigma)\n",
    "    # TODO fit and plot with color varying from collist\n",
    "\n",
    "plt.legend([\"training size : %d\" % n for n in range_n_samples],\n",
    "           loc='upper left')\n",
    "\n",
    "plt.close(6)\n",
    "plt.figure(6)\n",
    "plot_2d(X_train, Y_train)\n",
    "n_neighbors = 40\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "frontiere_new(knn, X_train, Y_train, w=None, step=50, alpha_choice=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#     Digits data\n",
    "############################################################################\n",
    "\n",
    "# Q9 : test k-NN on digits dataset\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "print(type(digits))\n",
    "# A Bunch is a subclass of 'dict' (dictionary)\n",
    "# help(dict)\n",
    "# see also \"http://docs.python.org/2/library/stdtypes.html#mapping-types-dict\"\n",
    "\n",
    "\n",
    "# inspect digits attributes:\n",
    "print(digits.keys())\n",
    "print(digits.target[:50])\n",
    "print(len(digits.data))\n",
    "print(digits.data[0])\n",
    "print(digits['data'][0])\n",
    "print(digits['images'][0])\n",
    "print(digits.data[0] == digits['data'][0])\n",
    "\n",
    "\n",
    "plt.close(7)\n",
    "plt.figure(7)\n",
    "for idx, (img, lbl) in enumerate(list(zip(digits.images,\n",
    "                                          digits.target))[10:20]):\n",
    "    plt.subplot(2, 5, idx + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='None')\n",
    "    plt.title('Training: %i' % lbl)\n",
    "\n",
    "n_samples = len(digits.data)\n",
    "\n",
    "X_train = \n",
    "Y_train = \n",
    "X_test = =\n",
    "Y_test = \n",
    "\n",
    "plt.figure()\n",
    "# todo plot histogram of Y_test\n",
    "\n",
    "\n",
    "# TODO fit, print score\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 : Compute confusion matrix\n",
    "\n",
    "CM = # TODO \n",
    "print(CM)\n",
    "\n",
    "# TODO normalize CM so that each row sums to 1\n",
    "CM_normalized = \n",
    "print(CM_normalized)\n",
    "plt.matshow(CM_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 : Estimate k with cross-validation\n",
    "\n",
    "# Have a look at the class  'LOOCurve', defined in the source file.\n",
    "\n",
    "\n",
    "loo_curve = # TODO\n",
    "# TODO fit it\n",
    "# TODO print cross val scores\n",
    "\n",
    "\n",
    "plt.close(9)\n",
    "plt.figure(9)\n",
    "# TODO plot curve\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
